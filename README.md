# Capstone_Project_2025
Complete the overview and opening statement.
Analyze the severity of COPD by age, how smoking and the number of packs smoked corresponds to the severity of copd (stages 1, 2, 3, 4) and how often other health issues occur COPD.  







===================================================================================================

Note: In the future as time allows, I plan to analyze this data further to find out how COPD rehabilitation improves the symptoms and severity of COPD by looking at the 6 minute walk test results, FEV1 scores, and other information, before and after pulmonary rehabilitation. This will require merging an additional dataset with the pulmonary rehabilitation information.
Finally, will look at the typical progression of COPD over time, with and without Pulmonary Rehabilitation, and what other factors may cause the progression to speed up or worsen. 

===================================================================================================


This project was completed and tested on a Chrome webbrowser.

# PROJECT LOCATION: 
My project can be found on GitHub. 
My profile name is TrishS7777
https://github.com/TrishS7777/Capstone_Project_2025_Patricia_Sullivan1.git


The 3 Datasets I used and merged were from Kaggle:

1) The COPD Dataset
   * read in as copd_dataset1 = pd.read_csv('dataset.csv')
   * webaddress: https://www.kaggle.com/code/anapharm/the-copd-dataset

2) Patient Risk Profiles
   * read in as copd_dataset2 = pd.read_csv('patient_risk_profiles.csv')
   * webaddress: https://www.kaggle.com/datasets/sujaykapadnis/patient-risk-profiles

3) Respiratory Symptoms and Treatment 
   * read in as copd_dataset3 = pd.read_csv('respiratory symptoms and treatment.csv')
   * webaddress: https://www.kaggle.com/datasets/abbotpatcher/respiratory-symptoms-and-treatment?select=respiratory+symptoms+and+treatment.csv






The 5 datasets found are:
*copd_dataset1
*copd_dataset2
*merged_copd_dataset1
*copd_dataset3
*merged_copd_dataset2

The first 2 datasets, 'copd_dataset 1' and 'copd_dataset2', were read in and cleaned, then merged into...'merged_copd_dataset1' and cleaned.
Next 'copd_dataset3' was read in and cleaned.
Finally, 'merged_copd_dataset1' was merged with 'copd_dataset3' to form the final 'merged_copd_dataset2'. 
This final dataset was then cleaned and analyzed.  


